这是一道很常见的面试题，但是大多数人并不知道怎么回答，这种问题其实可以有很多形式的提问方式：

面对业务急剧增长你怎么处理？

业务量增长10倍、100倍怎么处理？

你们系统怎么支撑高并发的？

怎么设计一个高并发系统？

... ...

诸如此类，问法很多，但是面试这种类型的问题，我们可以有一个常规的思路去回答，就是围绕支撑高并发的业务场景怎么设计系统才合理？如果你能想到这一点，那接下来我们就可以围绕高并发这个话题去阐述了，我大致归纳总结为以下几个点。本质上，这个问题就是综合考验你对各个细节是否知道怎么处理，是否有经验处理过而已。如果说面试是一张考卷，那么这道题就是最后一道大题，你不写就一点分数没有，只要你写了在点子上，就会给分数。

# 物理层面

这是最粗暴简单的方式，如果单台机器的qps只有100，那么理论上我们只要足够有钱，无限加机器就能抗住更高的并发了。理论上来说完全没有毛病，实际上有很多公司也确实这么干的，比如平时我们的qps只有200，几台机器就可以抗住这些请求了，但是到大促活动比如双11期间，面对流量剧增，qps可能到1000甚至更多，就可以通过临时增加服务器的方式来抗住流量的压力，活动结束后，再归还服务器就行了，以前在没有云服务器的时代可能还比较麻烦，现在通过各种云动态横向扩容很容易做到这一点。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj46exhfxuj30em0eawgt.jpg" style="zoom:50%;" />



# MQ

mq的作用很简单，削峰填谷。以电商交易下单的场景来说，正向交易的过程可能涉及到创建订单、扣减库存、扣减活动预算、扣减积分等等。每个接口的耗时如果是100ms，那么理论上整个下单的链路就是400ms，这个时间显然是太长了。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj46sujo8wj311o05k42n.jpg" style="zoom:50%;" />

如果这些操作全部同步处理的话，首先调用链路太长影响接口性能，其次分布式事务的问题很难处理，这时候像扣减预算和积分这种对实时一致性要求没有那么高的请求，完全就可以通过mq异步的方式去处理了。同时，考虑到异步带来的不一致的问题，我们可以通过job去重试保证接口调用成功，而且一般公司都会有核对的平台，比如下单成功但是未扣减积分的这种问题可以通过核对作为兜底的处理方案。这也是目前大部分公司的常见的处理方式。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj46xmxi6pj316i0d0wkq.jpg" alt="image-20200926174106778" style="zoom:50%;" />

这是mq作为在调用链路上起到的作用，另外，要清楚使用mq之后可能导致的问题，要阐述清楚。

## 消息丢失

使用mq之后，怎么保证消息的可靠性，消息不丢失是一个避不开的话题，主要有3个方面避免消息的丢失。

### 生产者发送失败

针对生产者发送消息的过程我们可以通过同步发送或者异步发送的方式来处理。但是如果同步发送的话，性能没区别，可以通过异步发送，然后二次ack确认的形式来做，异步发送成功之后，接收发送的回调。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj490bq2dbj30kc08c0v8.jpg" style="zoom:50%;" />

但是这个模式下还是有可能丢失，如果生产者发送之后宕机，消息没有持久化，消息丢失，无法重发，可以再加一张本地消息表保存发送的消息记录。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj493hs5y0j30js0eugot.jpg" alt="image-20200926185557235" style="zoom:50%;" />



### MQ丢失数据

如果消息发送成功，但是由于mq本身的问题导致消息丢失，可以采用同步、异步刷盘的方式来解决。以kafka来说，可以通过设置replication.factor>1，retries=MAX 等一些参数保证至少2个副本写入成功加上无限重试的方式来保证消息不丢失，至于中间性能和可靠性的保证要根据具体的业务处理。

### 消费者消费失败

这个场景就会比较少见，rocketmq这种只要你方法返回异常不主动确认的话，会一直重试，kafka可以设置手动确认的方式。当然了，消费的幂等性我们是要自己保证的。

消费方不返回ack确认，mq重发的机制根据mq类型的不同发送时间间隔、次数都不尽相同，如果重试超过次数之后会进入死信队列，需要手工来处理了。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj497vrf8nj30t20dmq63.jpg" style="zoom:50%;" />



## 消息顺序

在一些特殊的场景，是需要消息的顺序性的，比如下单之和在支付，下单成功消息和支付成功的消息是否需要保证顺序性？rocketmq可以支持消息顺序性，通常是保证分区消息的顺序性，比如使用订单id作为分区key，对于同一个订单来说他的消息就是顺序的。



# Redis

在下单的过程之前，用户首先进入的是提单页，又或者叫做订单确认页，这个页面的数据呈现一般会非常复杂，因为要显示的东西太多，会涉及到各个域的接口调用，提单页的性能是保证下单转化率的前提。考虑使用缓存首要必然是redis了。

比如在提单页你要看到商品的信息，商品、价格的信息根据场景来判断是否可以缓存，缓存的时间，这样可以提高页面的加载速度。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj47ipbrulj30ny0okjx9.jpg" style="zoom:40%;" />

此外，一般来说提单页会由交易本身或者导购的服务来做聚合，聚合调用接口可以做成多线程的方式，没有特殊的依赖性的话就没必要做成全部同步调用了。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj49hf8tr2j318k0oydqy.jpg" alt="image-20200926190920330" style="zoom:50%;" />

使用redis缓存之后，一些随之而来的问题是你必须要考虑的。

## 热key

所谓热key问题就是，突然有几十万的请求去访问redis上的某个特定key，那么这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机引发雪崩。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj49u21u0mj30t60c6dhx.jpg" alt="image-20200926192128843" style="zoom:50%;" />

针对热key的解决方案：

1. 提前把热key打散到不同的服务器
2. 加入二级缓存，提前加载热key数据到内存中，如果redis宕机，走内存查询

## 缓存击穿

击穿的概念就是单个key并发访问过高，过期时导致所有请求直接打到db上，这个和热key的问题比较类似，只是说的点在于过期导致请求全部打到DB上而已。

这个解决方案：

1. 加锁更新，比如请求查询A，发现缓存中没有，对A这个key加锁，同时去数据库查询数据，写入缓存，再返回给用户，这样后面的请求就可以从缓存中拿到数据了。
2. 将过期时间组合写在value中，通过异步的方式不断的刷新过期时间，防止此类现象。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj4a0tjc63j30oe0ccmz8.jpg" alt="image-20200926192758779" style="zoom:50%;" />

## 缓存穿透

穿透是指查询不存在缓存中的数据，每次请求都会打到DB，就像缓存不存在一样。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj4a3ig0dfj30ny0c2766.jpg" alt="image-20200926193033510" style="zoom:50%;" />

针对这个问题，加一层布隆过滤器。布隆过滤器的原理是在你存入数据的时候，会通过散列函数将它映射为一个位数组中的K个点，同时把他们置为1。

这样当用户再次来查询A，而A在布隆过滤器值为0，直接返回，就不会产生击穿请求打到DB了。

显然，使用布隆过滤器之后会有一个问题就是误判，因为它本身是一个数组，可能会有多个值落到同一个位置，那么理论上来说只要我们的数组长度够长，误判的概率就会越低，这种问题就根据实际情况来就好了。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj4aezvqokj30yu0f4goq.jpg" style="zoom:50%;" />

## 缓存雪崩

当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上，这样可能导致整个系统的崩溃，称为雪崩。雪崩和击穿、热key的问题不太一样的是，他是指大规模的缓存都过期失效了。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj4an5yjh5j30ra0catb2.jpg" style="zoom:50%;" />



针对雪崩几个解决方案：

1. 针对不同key设置不同的过期时间，避免同时过期
2. 限流，如果redis宕机，可以限流，避免同时刻大量请求打崩DB
3. 二级缓存，同热key的方案。



## 高可用

要想实现高可用，一台机器肯定是不够的，而redis要保证高可用，有3个可选方案。

### 主从

主从模式是最简单的实现高可用的方案，核心就是主从同步。主从同步的原理如下：

1. slave发送sync命令到master
2. master收到sync之后，执行bgsave，生成RDB全量文件
3. master把slave的写命令记录到缓存
4. bgsave执行完毕之后，发送RDB文件到slave，slave执行
5. master发送缓存中的写命令到slave，slave执行

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj4e2iy05pj30ne0eyabw.jpg" alt="image-20200926214800800" style="zoom:50%;" />

这里我写的这个命令是sync，但是在redis2.8版本之后已经使用psync来替代sync了，原因是sync命令非常消耗系统资源，而psync的效率更高。

### 哨兵

基于主从方案的缺点还是很明显的，假设master宕机，那么就不能写入数据，那么slave也就失去了作用，整个架构就不可用了，除非你手动切换主主要原因就是因为没有主备切换机制。而哨兵(sentinel)的功能比单纯的主从架构全面的多了，它具备自动故障转移、集群监控、消息通知等功能。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gj4enuv07pj30om0iwjuy.jpg" alt="image-20200926220830758" style="zoom:50%;" />

哨兵可以同时监视多个主从服务器，并且在被监视的master下线时，自动将某个slave提升为master，然后由新的master继续接收命令。整个过程如下：

1. 初始化sentinel，将普通的redis代码替换成sentinel专用代码
2. 初始化masters字典和服务器信息，服务器信息主要保存ip:port，并记录实例的地址和ID
3. 创建和master的两个连接，命令连接和订阅连接，并且订阅sentinel:hello频道
4. 每隔10秒向master发送info命令，获取master和它下面所有slave的当前信息
5. 当发现master有新的slave之后，sentinel和新的slave同样建立两个连接，同时每个10秒发送info命令，更新master信息
6. sentinel每个1秒向所有服务器发送ping命令，如果某台服务器在配置的响应时间内连续返回无效回复，将会被标记为下线状态
7. 选举出领头sentinel，领头sentinel需要半数以上的sentinel同意
8. 领头sentinel从已下线的的master所有slave中挑选一个，将其转换为master
9. 让所有的slave改为从新的master复制数据
10. 将原来的master设置为新的master的从服务器，当原来master重新回复连接时，就变成了新master的从服务器

### cluster





# Dubbo

既然都微服务化了，那接口调用如果还采用http的方式的话对性能的影响其实是挺大的，dubbo就应该拿出来单独说一说。

## 分层



## 负载均衡



## 工作原理



## 服务治理



## 熔断、限流、降级







# 数据库

## 读写分离

## 分库分表



# 总结